---
title: "20 - Production Deployment Guide"
description: "This comprehensive guide is intended for DevOps engineers, system administrators, and infrastructure teams responsible for deploying and maintaining the Peak RAG platform in production environments."
---

# 20 - Production Deployment Guide

This comprehensive guide is intended for DevOps engineers, system administrators, and infrastructure teams responsible for deploying and maintaining the Peak RAG platform in production environments.

---

## Overview

The Peak RAG platform is a distributed microservices application built on an NX monorepo architecture. It consists of TypeScript/Node.js services, Python AI/ML microservices, and several third-party dependencies that must be properly configured and orchestrated for production deployment.

### Architecture Components

- **Core API** (NestJS): Main backend service handling business logic
- **Admin Dashboard** (Next.js 15): Frontend management interface
- **Web SDK** (React): Embeddable widget for end-user interactions
- **Python Microservices**: Document validation, PDF ingestion, RAG evaluation
- **PostgreSQL**: Primary relational database
- **Weaviate**: Vector database for semantic search
- **Redis**: Caching and message queue backend
- **Keycloak or Azure Entra ID**: Identity and access management
- **S3/Azure Blob**: Object storage for documents
- **SMTP Server**: Email notifications

---

## Prerequisites

### System Requirements

- **Operating System**: Linux (Ubuntu 20.04+ recommended) or Docker-compatible environment
- **CPU**: Minimum 4 cores (8+ cores recommended for production)
- **RAM**: Minimum 16GB (32GB+ recommended for production)
- **Storage**:
  - 100GB+ for application and logs
  - Separate volumes for databases (PostgreSQL, Weaviate)
  - Object storage for documents (S3/Azure Blob)

### Required Software

- **Node.js**: v20.0.0 or higher
- **pnpm**: v9.7.1 or higher
- **Docker**: v24.x or higher (if using containerization)
- **Docker Compose**: v2.x or higher
- **PostgreSQL**: v14+ (can be external or containerized)
- **Git**: For source code management

### External Services

- **OpenAI API** or **Azure OpenAI Service**: Required for LLM operations
- **Keycloak** or **Azure Entra ID**: Authentication provider
- **S3-compatible storage** or **Azure Blob Storage**: Document storage
- **SMTP Server**: Email service (e.g., SendGrid, AWS SES)
- **Weaviate Cloud** or **Self-hosted Weaviate**: Vector database

---

## Part 1: Environment Configuration

### Critical Environment Variables

All application-level configuration is managed through environment variables. Create `.env` files for each service or use your deployment platform's secrets management.

#### API Service (`apps/api`)

```bash
# Server Configuration
PORT=4000
USE_JSON_LOGGER=true
DEBUG=false

# Database
POSTGRES_URL=postgresql://username:password@host:5432/rag_production?schema=public

# Weaviate Configuration
WEAVIATE_HOST=https://your-weaviate-cluster.weaviate.network
WEAVIATE_PORT=443
WEAVIATE_GRPC_HOST=grpc-your-weaviate-cluster.weaviate.network
WEAVIATE_GRPC_PORT=443
WEAVIATE_API_KEY=your-weaviate-api-key

# OpenAI Configuration (Standard)
OPENAI_API_KEY=sk-your-openai-api-key
OPENAI_EMBEDDING_MODEL=text-embedding-3-large
OPENAI_BATCH_MODEL=gpt-4o

# Azure OpenAI Configuration (Alternative)
OPENAI_AZURE_API_HOST=https://your-resource.openai.azure.com
OPENAI_AZURE_RESOURCE_NAME=your-resource-name
OPENAI_AZURE_API_GPT_VERSION=2024-08-01-preview
OPENAI_AZURE_API_ADA_VERSION=2024-02-01
AZURE_GPT_4O_DEPLOYMENT_ID=gpt-4o-deployment
AZURE_GPT_4O_MINI_DEPLOYMENT_ID=gpt-4o-mini-deployment
AZURE_GPT_41_DEPLOYMENT_ID=gpt-4-turbo-deployment
AZURE_GPT_41_MINI_DEPLOYMENT_ID=gpt-4-mini-deployment

# CORS Configuration
CORS_ALLOWED_ORIGINS=https://admin.yourcompany.com,https://app.yourcompany.com

# Authentication - Keycloak
AUTH_PROVIDER=keycloak
KEYCLOAK_CLIENT_ID=rag-api
KEYCLOAK_BASE_URL=https://auth.yourcompany.com
KEYCLOAK_REALM=production
KEYCLOAK_CLIENT_SECRET=your-keycloak-client-secret

# Authentication - Azure Entra ID (Alternative)
AUTH_PROVIDER=entra-id
JWKS_URL=https://login.microsoftonline.com/your-tenant-id/discovery/v2.0/keys
AZURE_ENTRA_ID_CLIENT_ID=your-application-client-id
AZURE_ENTRA_ID_JWT_ISSUER=https://login.microsoftonline.com/your-tenant-id/v2.0
AZURE_ENTRA_ID_TENANT_ID=your-tenant-id
AZURE_ENTRA_ID_CLIENT_SECRET=your-client-secret
AZURE_ENTRA_ID_CLIENT_SCOPES=https://graph.microsoft.com/.default

# Object Storage - S3
OBJECT_STORAGE_STRATEGY=S3
OBJECT_STORAGE_API_URL=https://s3.amazonaws.com
OBJECT_STORAGE_ACCESS_KEY_ID=your-aws-access-key-id
OBJECT_STORAGE_SECRET_ACCESS_KEY=your-aws-secret-access-key
OBJECT_STORAGE_DOCUMENTS_BUCKET=rag-documents-production
OBJECT_STORAGE_DOCUMENTS_BUCKET_PUBLIC_URL=https://your-bucket.s3.amazonaws.com
OBJECT_STORAGE_DOCUMENTS_KEY_PREFIX=documents/

# Object Storage - Azure Blob with Entra ID (Alternative)
OBJECT_STORAGE_STRATEGY=AZURE_BLOB_ENTRA_ID
OBJECT_STORAGE_API_URL=https://yourstorageaccount.blob.core.windows.net
OBJECT_STORAGE_ACCESS_KEY_ID=your-application-client-id
OBJECT_STORAGE_TENANT_ID=your-tenant-id
OBJECT_STORAGE_SECRET_ACCESS_KEY=your-application-client-secret
OBJECT_STORAGE_DOCUMENTS_BUCKET=rag-documents
OBJECT_STORAGE_DOCUMENTS_BUCKET_PUBLIC_URL=https://yourstorageaccount.blob.core.windows.net/rag-documents

# Redis Configuration
RAG_REDIS_HOST=redis.yourcompany.internal
RAG_REDIS_PORT=6379
RAG_REDIS_USERNAME=default
RAG_REDIS_PASSWORD=your-redis-password

# Email Configuration
EMAIL_SMTP_HOST=smtp.sendgrid.net
EMAIL_SMTP_PORT=587
EMAIL_SMTP_USER=apikey
EMAIL_SMTP_PASSWORD=your-sendgrid-api-key
EMAIL_FROM=noreply@yourcompany.com

# Microservices URLs
RAGAS_URL=http://ragas:8069
PDF_INGESTION_SERVICE_URL=http://pdf-ingestion:8000
DOCUMENT_VALIDATION_URL=http://document-validation:8070
DOCUMENT_VALIDATION_OCR_INPUT_MODE=url

# Azure Document Intelligence (Optional)
AZURE_DOCUMENT_INTELLIGENCE_KEY=your-azure-doc-intelligence-key
AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-resource.cognitiveservices.azure.com/
AZURE_DOCUMENT_INTELLIGENCE_API_VERSION=2024-07-31-preview

# Webhooks and URLs
WEBHOOK_BASE_URL=https://api.yourcompany.com
ADMIN_BASE_URL=https://admin.yourcompany.com

# Google Drive Integration (Optional)
GOOGLE_DRIVE_CLIENT_ID=your-google-client-id
GOOGLE_DRIVE_CLIENT_SECRET=your-google-client-secret

# Feature Flags
ENABLE_PERSONAL_DATA_DETECTION_SERVICE=false
PERSONAL_DATA_DETECTION_SERVICE_DRY_RUN_MODE=true
```

#### Admin Dashboard (`apps/admin`)

```bash
# Authentication - Keycloak
NEXT_PUBLIC_AUTH_PROVIDER=keycloak
KEYCLOAK_ID=admin-dashboard
KEYCLOAK_SECRET=your-keycloak-admin-client-secret
KEYCLOAK_BASE_URL=https://auth.yourcompany.com
KEYCLOAK_REALM=production

# Authentication - Azure Entra ID (Alternative)
NEXT_PUBLIC_AUTH_PROVIDER=entra-id
AZURE_ENTRA_ID_CLIENT_ID=your-admin-app-client-id
AZURE_ENTRA_ID_CLIENT_SECRET=your-admin-app-client-secret
AZURE_ENTRA_ID_ISSUER=https://login.microsoftonline.com/your-tenant-id/v2.0
AZURE_ENTRA_ID_APPLICATION_ID_URI=api://your-admin-app-id
AZURE_ENTRA_ID_TENANT_ID=your-tenant-id

# NextAuth Configuration
AUTH_URL=https://admin.yourcompany.com
AUTH_SECRET=your-nextauth-secret-minimum-32-characters
NEXT_PUBLIC_BASE_URL=https://admin.yourcompany.com
NEXT_PUBLIC_BASE_PATH=/

# Backend API
BACKEND_URL=http://api:4000

# Feature Flags
NEXT_PUBLIC_SLOT_FILLING_DEBUG=false
```

#### Web SDK (`apps/web-sdk`)

```bash
VITE_RAG_API_URL=https://api.yourcompany.com
```

#### Python Microservices

**Document Validation Service:**

```bash
HOST=0.0.0.0
PORT=8070
OPENAI_API_KEY=sk-your-openai-api-key
MISTRAL_API_KEY=your-mistral-api-key
AZURE_DOCUMENT_INTELLIGENCE_KEY=your-azure-key
AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-resource.cognitiveservices.azure.com/
AZURE_DOCUMENT_INTELLIGENCE_API_VERSION=2024-07-31-preview
```

**PDF Ingestion Service:**

```bash
HOST=0.0.0.0
PORT=8000
OPENAI_API_KEY=sk-your-openai-api-key
```

**RAGAS Evaluation Service:**

```bash
HOST=0.0.0.0
PORT=8069
OPENAI_API_KEY=sk-your-openai-api-key
```

---

## Part 2: Database Setup

### PostgreSQL Database

#### Initial Setup

```bash
# Create database
createdb rag_production

# Or via SQL
psql -U postgres -c "CREATE DATABASE rag_production;"
```

#### Run Migrations

```bash
# Navigate to project root
cd /path/to/rag

# Install dependencies
pnpm install --frozen-lockfile

# Generate Prisma client
pnpm exec nx run db:prisma-generate

# Apply migrations
pnpm exec nx run db:prisma-deploy
```

#### Seed Initial Data (Optional)

```bash
# Load seed data for demo purposes
pnpm exec nx run db:prisma-seed
```

**Warning**: Only run seed in development or staging. Production should start with a clean database.

#### Backup Strategy

```bash
# Daily backup script
#!/bin/bash
BACKUP_DIR="/backups/postgresql"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
pg_dump -U postgres -h localhost rag_production | gzip > "$BACKUP_DIR/rag_backup_$TIMESTAMP.sql.gz"

# Rotate old backups (keep 30 days)
find $BACKUP_DIR -name "rag_backup_*.sql.gz" -mtime +30 -delete
```

### Weaviate Vector Database

#### Self-Hosted Weaviate

Use the provided `docker-compose` or deploy via Kubernetes:

```yaml
# docker-compose.weaviate.yml
services:
  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.28.4
    ports:
      - "8080:8080"
      - "50051:50051"
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "false"
      AUTHENTICATION_APIKEY_ENABLED: "true"
      AUTHENTICATION_APIKEY_ALLOWED_KEYS: "your-production-api-key"
      AUTHENTICATION_APIKEY_USERS: "rag-api"
      PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
      DEFAULT_VECTORIZER_MODULE: "none"
      ENABLE_MODULES: "text2vec-openai,reranker-transformers"
      ENABLE_API_BASED_MODULES: "true"
      CLUSTER_HOSTNAME: "node1"
      OPENAI_APIKEY: "sk-your-openai-api-key"
      RERANKER_INFERENCE_API: "http://reranker-transformers:8080"
    volumes:
      - weaviate_data:/var/lib/weaviate

  reranker-transformers:
    image: cr.weaviate.io/semitechnologies/reranker-transformers:cross-encoder-ms-marco-MiniLM-L-6-v2
    environment:
      ENABLE_CUDA: "0"

volumes:
  weaviate_data:
```

#### Weaviate Cloud (Recommended for Production)

1. Sign up at https://console.weaviate.cloud/
2. Create a production cluster
3. Note the cluster URL and API key
4. Configure in API environment variables

---

## Part 3: Deployment Strategies

### Option 1: Docker Compose Deployment

#### Production Docker Compose

```yaml
# docker-compose.prod.yml
services:
  api:
    image: your-registry.com/rag-api:latest
    build:
      context: .
      dockerfile: apps/api/Dockerfile
    ports:
      - "4000:4000"
    env_file:
      - .env.api
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/api/rag/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  admin:
    image: your-registry.com/rag-admin:latest
    build:
      context: .
      dockerfile: apps/admin/Dockerfile
    ports:
      - "3000:3000"
    env_file:
      - .env.admin
    depends_on:
      - api
    restart: unless-stopped

  pdf-ingestion:
    image: your-registry.com/rag-pdf-ingestion:latest
    build:
      context: .
      dockerfile: apps/pdf-ingestion-service/Dockerfile
    ports:
      - "8000:8000"
    env_file:
      - .env.pdf
    restart: unless-stopped

  document-validation:
    image: your-registry.com/rag-document-validation:latest
    build:
      context: .
      dockerfile: apps/document-validation/Dockerfile
    ports:
      - "8070:8070"
    env_file:
      - .env.docval
    restart: unless-stopped

  ragas:
    image: your-registry.com/rag-ragas:latest
    build:
      context: .
      dockerfile: apps/ragas/Dockerfile
    ports:
      - "8069:8069"
    env_file:
      - .env.ragas
    restart: unless-stopped

  postgres:
    image: postgres:14-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: rag_production
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    command: ["redis-server", "--requirepass", "${REDIS_PASSWORD}", "--appendonly", "yes"]
    volumes:
      - redis_data:/data
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - api
      - admin
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
```

#### Deployment Commands

```bash
# Build images
docker compose -f docker-compose.prod.yml build

# Start services
docker compose -f docker-compose.prod.yml up -d

# View logs
docker compose -f docker-compose.prod.yml logs -f

# Stop services
docker compose -f docker-compose.prod.yml down
```

### Option 2: Kubernetes Deployment

#### Namespace and ConfigMaps

```yaml
# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: rag-production

---
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: rag-api-config
  namespace: rag-production
data:
  PORT: "4000"
  USE_JSON_LOGGER: "true"
  DEBUG: "false"
```

#### Secrets

```yaml
# secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: rag-secrets
  namespace: rag-production
type: Opaque
stringData:
  POSTGRES_URL: postgresql://user:pass@postgres:5432/rag_production
  OPENAI_API_KEY: sk-your-key-here
  KEYCLOAK_CLIENT_SECRET: your-secret-here
```

#### API Deployment

```yaml
# api-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rag-api
  namespace: rag-production
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rag-api
  template:
    metadata:
      labels:
        app: rag-api
    spec:
      containers:
        - name: api
          image: your-registry.com/rag-api:latest
          ports:
            - containerPort: 4000
          envFrom:
            - configMapRef:
                name: rag-api-config
            - secretRef:
                name: rag-secrets
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "2Gi"
              cpu: "1000m"
          livenessProbe:
            httpGet:
              path: /api/rag/health
              port: 4000
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /api/rag/health
              port: 4000
            initialDelaySeconds: 5
            periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: rag-api
  namespace: rag-production
spec:
  selector:
    app: rag-api
  ports:
    - port: 4000
      targetPort: 4000
  type: ClusterIP
```

#### Ingress Configuration

```yaml
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: rag-ingress
  namespace: rag-production
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - api.yourcompany.com
        - admin.yourcompany.com
      secretName: rag-tls
  rules:
    - host: api.yourcompany.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: rag-api
                port:
                  number: 4000
    - host: admin.yourcompany.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: rag-admin
                port:
                  number: 3000
```

### Option 3: Cloud Platform Deployments

#### Railway

The project includes `railway.json` files for easy Railway deployment:

```bash
# Install Railway CLI
npm i -g @railway/cli

# Login
railway login

# Link project
railway link

# Deploy
railway up
```

#### AWS ECS/Fargate

1. Build and push Docker images to ECR
2. Create ECS task definitions for each service
3. Configure Application Load Balancer
4. Set up RDS for PostgreSQL
5. Use AWS Secrets Manager for environment variables

#### Azure Container Apps

1. Build and push images to Azure Container Registry
2. Create Container Apps for each service
3. Configure Azure Database for PostgreSQL
4. Use Azure Key Vault for secrets
5. Set up Application Gateway for ingress

---

## Part 4: Security Hardening

### Application Security

#### API Rate Limiting

Configure rate limiting in API environment:

```bash
RATE_LIMIT_PER_USER_PER_MINUTE=100
RATE_LIMIT_PER_IP_PER_MINUTE=1000
```

#### CORS Configuration

Strictly limit allowed origins:

```bash
# Production - specific domains only
CORS_ALLOWED_ORIGINS=https://admin.yourcompany.com,https://app.yourcompany.com

# Never use in production
# CORS_ALLOWED_ORIGINS=*
```

#### API Secret Rotation

API secrets are generated during application creation. To rotate:

1. Generate new secret via admin API
2. Update integrations with new secret
3. Old secret becomes invalid immediately

### Database Security

```sql
-- Create read-only user for reporting
CREATE USER rag_readonly WITH PASSWORD 'secure-password';
GRANT CONNECT ON DATABASE rag_production TO rag_readonly;
GRANT USAGE ON SCHEMA public TO rag_readonly;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO rag_readonly;

-- Enable row-level security for multi-tenancy
ALTER TABLE "Application" ENABLE ROW LEVEL SECURITY;
```

### Network Security

#### Firewall Rules

- **API**: Only accessible from load balancer
- **Admin**: Only accessible from load balancer
- **PostgreSQL**: Only accessible from API service
- **Redis**: Only accessible from API service
- **Weaviate**: Only accessible from API service

#### TLS/SSL

All external communication must use TLS 1.2+:

```nginx
# nginx.conf
server {
    listen 443 ssl http2;
    server_name api.yourcompany.com;

    ssl_certificate /etc/nginx/ssl/fullchain.pem;
    ssl_certificate_key /etc/nginx/ssl/privkey.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;

    location / {
        proxy_pass http://api:4000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

---

## Part 5: Monitoring and Observability

### Prometheus Metrics

The API exposes Prometheus metrics at `/metrics`:

```yaml
# prometheus.yml
scrape_configs:
  - job_name: "rag-api"
    static_configs:
      - targets: ["api:4000"]
    metrics_path: "/metrics"
    bearer_token: "your-metrics-token"

  - job_name: "weaviate"
    static_configs:
      - targets: ["weaviate:2112"]
```

### Grafana Dashboards

Pre-built dashboards are available in `monitoring/grafana/`:

- **API Performance**: Request rates, latency, error rates
- **LLM Usage**: Token consumption, costs, model performance
- **Database Health**: Connection pools, query performance
- **Weaviate Metrics**: Vector search performance, index size

Import dashboards:

```bash
# Copy dashboards to Grafana
cp monitoring/grafana/dashboards/*.json /var/lib/grafana/dashboards/
```

### Log Aggregation

#### Structured JSON Logging

Enable in production:

```bash
USE_JSON_LOGGER=true
```

#### Log Shipping (Example with Fluentd)

```conf
# fluentd.conf
<source>
  @type tail
  path /var/log/containers/rag-*.log
  pos_file /var/log/fluentd/rag.log.pos
  tag rag.*
  format json
</source>

<match rag.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  index_name rag-logs
  type_name _doc
</match>
```

### Health Checks

Each service exposes health endpoints:

- **API**: `GET /api/rag/health` → `200 OK`
- **Admin**: `GET /api/health` → `200 OK`

Configure monitoring to alert on health check failures.

---

## Part 6: Backup and Disaster Recovery

### Database Backups

#### Automated Backup Script

```bash
#!/bin/bash
# /opt/scripts/backup-rag-db.sh

set -e

BACKUP_DIR="/backups/postgresql"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

# Create backup
echo "Starting backup at $(date)"
pg_dump -U postgres -h db.yourcompany.internal rag_production | gzip > "$BACKUP_DIR/rag_backup_$TIMESTAMP.sql.gz"

# Upload to S3
aws s3 cp "$BACKUP_DIR/rag_backup_$TIMESTAMP.sql.gz" s3://your-backup-bucket/postgresql/

# Rotate local backups
find $BACKUP_DIR -name "rag_backup_*.sql.gz" -mtime +$RETENTION_DAYS -delete

echo "Backup completed at $(date)"
```

#### Cron Schedule

```cron
# Daily backup at 2 AM
0 2 * * * /opt/scripts/backup-rag-db.sh >> /var/log/rag-backup.log 2>&1
```

### Weaviate Backups

```bash
# Backup Weaviate data directory
tar -czf weaviate_backup_$(date +%Y%m%d).tar.gz /var/lib/weaviate/

# Or use Weaviate backup API
curl -X POST https://your-weaviate-cluster.weaviate.network/v1/backups/filesystem \
  -H "Authorization: Bearer ${WEAVIATE_API_KEY}" \
  -H "Content-Type: application/json" \
  -d '{
    "id": "backup-'$(date +%Y%m%d)'",
    "include": ["ApplicationData"]
  }'
```

### Disaster Recovery Plan

1. **Database Restore**:

   ```bash
   gunzip < rag_backup_20241106.sql.gz | psql -U postgres rag_production
   ```

2. **Weaviate Restore**:

   ```bash
   # Stop Weaviate
   # Extract backup
   tar -xzf weaviate_backup_20241106.tar.gz -C /
   # Start Weaviate
   ```

3. **Application Redeployment**:
   ```bash
   docker compose -f docker-compose.prod.yml pull
   docker compose -f docker-compose.prod.yml up -d
   ```

**RTO (Recovery Time Objective)**: 1-2 hours  
**RPO (Recovery Point Objective)**: 24 hours (daily backups)

---

## Part 7: Scaling Considerations

### Horizontal Scaling

#### API Service

```yaml
# Scale API replicas
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: rag-api-hpa
  namespace: rag-production
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: rag-api
  minReplicas: 3
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
```

### Database Scaling

#### PostgreSQL Read Replicas

```yaml
# Configure read replicas
services:
  postgres-primary:
    image: postgres:14
    environment:
      POSTGRES_REPLICATION_USER: replicator
      POSTGRES_REPLICATION_PASSWORD: repl_password

  postgres-replica:
    image: postgres:14
    environment:
      PGDATA: /var/lib/postgresql/data
    command: |
      postgres 
      -c wal_level=replica 
      -c hot_standby=on 
      -c max_wal_senders=3
```

Update connection string to use read replicas for queries:

```bash
POSTGRES_URL=postgresql://user:pass@postgres-primary:5432/rag_production
POSTGRES_READ_URL=postgresql://user:pass@postgres-replica:5432/rag_production
```

### Weaviate Scaling

For high-traffic deployments, use Weaviate Cloud with auto-scaling or configure a Weaviate cluster.

---

## Part 8: Troubleshooting

### Common Issues

#### API Won't Start

```bash
# Check logs
docker logs rag-api

# Common causes:
# 1. Database connection failed
# 2. Missing environment variables
# 3. Migrations not applied

# Solution:
pnpm exec nx run db:prisma-deploy
pnpm exec nx run db:prisma-generate
```

#### High Memory Usage

```bash
# Check Node.js memory
NODE_OPTIONS="--max-old-space-size=4096"

# Monitor with htop or container stats
docker stats

# Kubernetes resource limits
kubectl top pods -n rag-production
```

#### Weaviate Connection Timeouts

```bash
# Check Weaviate health
curl https://your-weaviate-cluster.weaviate.network/v1/.well-known/ready

# Verify API key
curl -H "Authorization: Bearer ${WEAVIATE_API_KEY}" \
  https://your-weaviate-cluster.weaviate.network/v1/meta
```

#### Token Limit Exceeded (OpenAI)

```bash
# Check token usage in Prometheus
# Reduce Result Limit in agent configuration
# Consider upgrading OpenAI tier
```

### Support and Documentation

- **Internal Documentation**: `/docs` directory in repository
- **API Documentation**: `https://your-api-url/api/docs` (OpenAPI/Swagger)
- **GitHub Issues**: For bug reports and feature requests

---

## Part 9: Maintenance

### Regular Tasks

#### Weekly

- Review application logs for errors
- Check disk space on database servers
- Verify backup completion

#### Monthly

- Update dependencies (security patches)
- Review and optimize database queries
- Analyze cost reports (LLM usage)

#### Quarterly

- Security audit
- Performance benchmarking
- Disaster recovery drill

### Update Procedure

```bash
# 1. Backup current state
./scripts/backup-all.sh

# 2. Pull latest code
git fetch origin
git checkout v1.2.0  # Use specific version tag

# 3. Install dependencies
pnpm install --frozen-lockfile

# 4. Generate Prisma client
pnpm exec nx run db:prisma-generate

# 5. Run migrations
pnpm exec nx run db:prisma-deploy

# 6. Build services
pnpm exec nx run api:build
pnpm exec nx run admin:build

# 7. Deploy with zero-downtime
# (Use rolling update in Kubernetes or blue-green in Docker)
```

---

## Part 10: Cost Optimization

### LLM Cost Management

- Monitor token usage via `/metrics` endpoint
- Set up alerts for unusual consumption
- Use `gpt-4o-mini` for simpler tasks
- Implement response caching (already built-in)
- Configure appropriate `Result Limit` values

### Infrastructure Cost

- Use spot/preemptible instances for non-critical services
- Enable auto-scaling to reduce idle resources
- Use Weaviate Cloud pay-as-you-go pricing
- Implement CDN for static assets (admin dashboard)
- Consider reserved instances for databases

---

## Deployment Checklist

Before going to production, verify:

- [ ] All environment variables configured
- [ ] Database migrations applied
- [ ] SSL/TLS certificates installed and valid
- [ ] Backups scheduled and tested
- [ ] Monitoring and alerting configured
- [ ] Log aggregation working
- [ ] Health checks passing
- [ ] Load testing completed
- [ ] Security scan performed
- [ ] Disaster recovery plan documented
- [ ] Team trained on operations
- [ ] On-call rotation established

---

## Conclusion

This deployment guide provides a comprehensive foundation for running the Peak RAG platform in production. Adapt the configurations to your specific infrastructure requirements and organizational policies. Always test changes in staging before applying to production.

For questions or issues not covered in this guide, consult the internal documentation or contact the platform engineering team.
